{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b10697",
   "metadata": {},
   "source": [
    "# Breast Cancer Histology Imaging\n",
    "mkfold.py -- from: https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis/\n",
    "(Spanhol et al., 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only one time!\n",
    "\n",
    "# %run mkfold.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e1714",
   "metadata": {},
   "source": [
    "# Keras Modeling\n",
    "Processing and SimpleCNN models adapted from: https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b97d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.image as mpimg\n",
    "import itertools\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizer_v1 import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,Convolution2D,BatchNormalization\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b100dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling data with 2 classes\n",
    "\n",
    "# labels = ['B', 'M']\n",
    "img_size = 224\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    path = data_dir\n",
    "    for img in os.listdir(path):\n",
    "        if img[4] == 'B':\n",
    "            class_num = 0\n",
    "        else:\n",
    "            class_num = 1\n",
    "        try:\n",
    "            img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
    "            resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "            data.append([resized_arr, class_num])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef659094",
   "metadata": {},
   "source": [
    "# Import data from all magnifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40X MAG\n",
    "\n",
    "train41 = get_data('./fold1/train/40X')\n",
    "val41 = get_data('./fold1/test/40X')\n",
    "\n",
    "train42 = get_data('./fold2/train/40X')\n",
    "val42 = get_data('./fold2/test/40X')\n",
    "\n",
    "train43 = get_data('./fold3/train/40X')\n",
    "val43 = get_data('./fold3/test/40X')\n",
    "\n",
    "train44 = get_data('./fold4/train/40X')\n",
    "val44 = get_data('./fold4/test/40X')\n",
    "\n",
    "train45 = get_data('./fold5/train/40X')\n",
    "val45= get_data('./fold5/test/40X')\n",
    "\n",
    "train_set40 = [train41, train42, train43, train44, train45]\n",
    "val_set40 = [val41, val42, val43, val44, val45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 MAG\n",
    "\n",
    "train1 = get_data('./fold1/train/100X')\n",
    "val1 = get_data('./fold1/test/100X')\n",
    "\n",
    "train2 = get_data('./fold2/train/100X')\n",
    "val2 = get_data('./fold2/test/100X')\n",
    "\n",
    "train3 = get_data('./fold3/train/100X')\n",
    "val3 = get_data('./fold3/test/100X')\n",
    "\n",
    "train4 = get_data('./fold4/train/100X')\n",
    "val4 = get_data('./fold4/test/100X')\n",
    "\n",
    "train5 = get_data('./fold5/train/100X')\n",
    "val5= get_data('./fold5/test/100X')\n",
    "\n",
    "train_set100 = [train1, train2, train3, train4, train5]\n",
    "val_set100 = [val1, val2, val3, val4, val5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200X Mag\n",
    "\n",
    "train21 = get_data('./fold1/train/200X')\n",
    "val21 = get_data('./fold1/test/200X')\n",
    "\n",
    "train22 = get_data('./fold2/train/200X')\n",
    "val22 = get_data('./fold2/test/200X')\n",
    "\n",
    "train23 = get_data('./fold3/train/200X')\n",
    "val23 = get_data('./fold3/test/200X')\n",
    "\n",
    "train24 = get_data('./fold4/train/200X')\n",
    "val24 = get_data('./fold4/test/200X')\n",
    "\n",
    "train25 = get_data('./fold5/train/200X')\n",
    "val25= get_data('./fold5/test/200X')\n",
    "\n",
    "train_set200 = [train21, train22, train23, train24, train25]\n",
    "val_set200 = [val21, val22, val23, val24, val25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73959091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400X Mag\n",
    "train421 = get_data('./fold1/train/400X')\n",
    "val421 = get_data('./fold1/test/400X')\n",
    "\n",
    "train422 = get_data('./fold2/train/400X')\n",
    "val422 = get_data('./fold2/test/400X')\n",
    "\n",
    "train423 = get_data('./fold3/train/400X')\n",
    "val423 = get_data('./fold3/test/400X')\n",
    "\n",
    "train424 = get_data('./fold4/train/400X')\n",
    "val424 = get_data('./fold4/test/400X')\n",
    "\n",
    "train425 = get_data('./fold5/train/400X')\n",
    "val425= get_data('./fold5/test/400X')\n",
    "\n",
    "train_set400 = [train421, train422, train423, train424, train425]\n",
    "val_set400 = [val421, val422, val423, val424, val425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba29796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing and Augmentation\n",
    "\n",
    "def processing(train, val):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "\n",
    "    for feature, label in train:\n",
    "        x_train.append(feature)\n",
    "        y_train.append(label)\n",
    "\n",
    "    for feature, label in val:\n",
    "        x_val.append(feature)\n",
    "        y_val.append(label)\n",
    "\n",
    "    # Normalize the data\n",
    "    x_train = np.array(x_train) /255\n",
    "    x_val = np.array(x_val) /255\n",
    "\n",
    "    x_train.reshape(-1, img_size, img_size, 1)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    x_val.reshape(-1, img_size, img_size, 1)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3915e",
   "metadata": {},
   "source": [
    "# SimpleCNN and SimpleCNN2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple CNN model with 3 Convolutional Layers followed by max-pooling layers + dropout layer (to avoid overfitting)\n",
    "def simpleCNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f5f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple CNN model with 3 Convolutional Layers followed by max-pooling layers + dropout layer (to avoid overfitting)\n",
    "def simpleCNN_2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Conv2D(128, 3,padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "\n",
    "    model.add(Conv2D(256, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    \n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CNN(x_train, y_train, x_val, y_val, model, epochs):\n",
    "    # Using Adam Optimzer and SparseCategoricalCrossentropy \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "    ls = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(optimizer = opt , loss = ls , metrics = ['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=epochs, validation_data = (x_val, y_val))\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    predict_x=model.predict(x_val) \n",
    "    predictions=np.argmax(predict_x,axis=1)\n",
    "    predictions = predictions.reshape(1,-1)[0]\n",
    "\n",
    "    print(classification_report(y_val, predictions, target_names = ['Benign (Class 0)','Malignant (Class 1)']))\n",
    "    print(confusion_matrix(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ec908",
   "metadata": {},
   "source": [
    "# Run SimpleCNN on all Magnifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d716bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleCNN model summary\n",
    "model = simpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86097ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40X\n",
    "\n",
    "for i in range(len(train_set40)):\n",
    "    print(\"THIS IS FOLD\", i+1)\n",
    "    x_train, y_train, x_val, y_val = processing(train_set40[i], val_set40[i])\n",
    "    model = simpleCNN()\n",
    "    run_CNN(x_train, y_train, x_val, y_val, model, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100X\n",
    "\n",
    "for i in range(len(train_set40)):\n",
    "    print(\"THIS IS FOLD\", i+1)\n",
    "    x_train, y_train, x_val, y_val = processing(train_set100[i], val_set100[i])\n",
    "    model = simpleCNN()\n",
    "    run_CNN(x_train, y_train, x_val, y_val, model, 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ad702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200X\n",
    "\n",
    "for i in range(len(train_set200)):\n",
    "    print(\"THIS IS FOLD\", i+1)\n",
    "    x_train, y_train, x_val, y_val = processing(train_set200[i], val_set200[i])\n",
    "    model = simpleCNN()\n",
    "    run_CNN(x_train, y_train, x_val, y_val, model, 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd20595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400X\n",
    "\n",
    "for i in range(len(train_set400)):\n",
    "    print(\"THIS IS FOLD\", i+1)\n",
    "    x_train, y_train, x_val, y_val = processing(train_set400[i], val_set400[i])\n",
    "    model = simpleCNN()\n",
    "    run_CNN(x_train, y_train, x_val, y_val, model, 100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc1cbe",
   "metadata": {},
   "source": [
    "# SimpleCNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleCNN2 Model Summary\n",
    "model = simpleCNN_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleCNN2, 200X Mag (all folds)\n",
    "\n",
    "for i in range(len(train_set200)):\n",
    "    print(\"THIS IS FOLD\", i+1)\n",
    "    x_train, y_train, x_val, y_val = processing(train_set200[i], val_set200[i])\n",
    "    model = simpleCNN_2()\n",
    "    run_CNN(x_train, y_train, x_val, y_val, model, 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b542b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainnew200 = [train23, train24, train25]\n",
    "valnew200 = [val23, val24, val25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleCNN2, 200X Mag (folds 3-5 after force quit)\n",
    "\n",
    "for i in range(len(trainnew200)):\n",
    "    print(\"THIS IS FOLD\", i+3)\n",
    "    x_train, y_train, x_val, y_val = processing(trainnew200[i], valnew200[i])\n",
    "    model = simpleCNN()\n",
    "    run_CNN(x_train, y_train, x_val, y_val, model, 100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d0e8f",
   "metadata": {},
   "source": [
    "# DenseNet\n",
    "Model adapted from https://www.pluralsight.com/guides/introduction-to-densenet-with-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNetModel(x_train, y_train, x_val, y_val, epochs):\n",
    "    model_d=DenseNet121(weights='imagenet',include_top=False, input_shape=(224, 224, 3)) \n",
    "\n",
    "    x=model_d.output\n",
    "\n",
    "    x= GlobalAveragePooling2D()(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x= Dropout(0.5)(x)\n",
    "    x= Dense(1024,activation='relu')(x) \n",
    "    x= Dense(512,activation='relu')(x) \n",
    "    x= BatchNormalization()(x)\n",
    "    x= Dropout(0.5)(x)\n",
    "\n",
    "    preds=Dense(2,activation='softmax')(x) #FC-layer\n",
    "    \n",
    "    model=Model(model_d.input, preds)\n",
    "    \n",
    "    for layer in model.layers[:-8]:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    for layer in model.layers[-8:]:\n",
    "        layer.trainable=True\n",
    "    \n",
    "#     model.summary()\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "    checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n",
    "    \n",
    "    # Fits-the-model\n",
    "    history = model.fit(x_train, y_train,\n",
    "                   epochs=epochs,\n",
    "                   verbose=1,\n",
    "                   callbacks=[anne, checkpoint],\n",
    "                   validation_data=(x_val, y_val))\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986559ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDenseNet(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    predict_x=model.predict(x_val) \n",
    "    predictions=np.argmax(predict_x,axis=1)\n",
    "    predictions = predictions.reshape(1,-1)[0]\n",
    "    \n",
    "    rounded_labels=np.argmax(y_val, axis=1)\n",
    "\n",
    "    print(classification_report(rounded_labels, predictions))\n",
    "    \n",
    "    cm = confusion_matrix(rounded_labels, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "for i in range(len(train_set200)):\n",
    "    print(\"THIS IS FOLD\", i+1)\n",
    "    x_train, y_train, x_val, y_val = processing(train_set200[i], val_set200[i])\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    history = DenseNetModel(x_train, y_train, x_val, y_val, epochs) \n",
    "    runDenseNet(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba244074",
   "metadata": {},
   "source": [
    "# VGG16\n",
    "Model adapted from https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c and https://medium.com/analytics-vidhya/multi-class-image-classification-using-transfer-learning-with-deep-convolutional-neural-networks-eab051cde3fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a03b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt VGG16 from scratch-- did not work well\n",
    "# Adapted from https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c \n",
    "\n",
    "# def VGG16_1(x_train, y_train, x_val, y_val, vgg_epoch):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "#     model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "#     model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "#     model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "#     model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(units=4096,activation=\"relu\"))\n",
    "#     model.add(Dense(units=4096,activation=\"relu\"))\n",
    "#     model.add(Dense(units=2, activation=\"softmax\"))\n",
    "    \n",
    "#     model.summary()\n",
    "    \n",
    "#     y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "#     y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    \n",
    "#     number_of_epochs = vgg_epoch\n",
    "#     vgg16_filepath = '/tmp/checkpoint'\n",
    "#     vgg_checkpoint = tf.keras.callbacks.ModelCheckpoint(vgg16_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#     vgg_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
    "    \n",
    "    \n",
    "#     opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "#     ls = tf.keras.losses.CategoricalCrossentropy()\n",
    "#     opt = Adam(lr=0.001)\n",
    "#     model.compile(optimizer=opt, loss=ls, metrics=['accuracy'])\n",
    "#     history = model.fit(x_train, y_train, epochs=epochs, validation_data = (x_val, y_val), callbacks=[vgg_checkpoint,vgg_early_stopping],verbose=1)\n",
    "    \n",
    "#     return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer-Learning: Pretrained VGG16\n",
    "# Adapted from https://medium.com/analytics-vidhya/multi-class-image-classification-using-transfer-learning-with-deep-convolutional-neural-networks-eab051cde3fb\n",
    "\n",
    "def VGG16_2(x_train, y_train, x_val, y_val, vgg_epoch):\n",
    "    vgg16_model = VGG16(pooling='avg', weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    for layers in vgg16_model.layers:\n",
    "        layers.trainable=False\n",
    "    last_output = vgg16_model.layers[-1].output\n",
    "    vgg_x = Flatten()(last_output)\n",
    "    vgg_x = Dense(128, activation = 'relu')(vgg_x)\n",
    "    vgg_x = Dense(128, activation = 'relu')(vgg_x)\n",
    "    vgg_x = Dense(2, activation = 'softmax')(vgg_x)\n",
    "    vgg16_final_model = tf.keras.Model(vgg16_model.input, vgg_x)\n",
    "    vgg16_final_model.compile(loss = 'categorical_crossentropy', optimizer= 'adam', metrics=['acc'])\n",
    "    \n",
    "    vgg16_final_model.summary()\n",
    "\n",
    "#   VGG16\n",
    "    number_of_epochs = vgg_epoch\n",
    "    vgg16_filepath = 'vgg_16_'+'-saved-model-{epoch:02d}-acc-{val_acc:.2f}.hdf5'\n",
    "    vgg_checkpoint = tf.keras.callbacks.ModelCheckpoint(vgg16_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    vgg_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)\n",
    "    \n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    \n",
    "    vgg16_history = vgg16_final_model.fit(x_train, y_train, epochs = number_of_epochs, validation_data = (x_val, y_val),callbacks=[vgg_checkpoint,vgg_early_stopping],verbose=1)\n",
    "\n",
    "    return vgg16_final_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runVGG16(history):\n",
    "    # Using Adam Optimzer and SparseCategoricalCrossentropy     \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(21)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    predict_x=model.predict(x_val) \n",
    "    predictions=np.argmax(predict_x,axis=1)\n",
    "    predictions = predictions.reshape(1,-1)[0]\n",
    "\n",
    "    print(classification_report(y_val, predictions, target_names = ['Benign (Class 0)','Malignant (Class 1)']))\n",
    "    print(confusion_matrix(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_data(model_vgg16, epochs):\n",
    "    acc = model_vgg16.history.history['acc']\n",
    "    val_acc = model_vgg16.history.history['val_acc']\n",
    "    loss = model_vgg16.history.history['loss']\n",
    "    val_loss = model_vgg16.history.history['val_loss']\n",
    "    epochs_range = range(epochs)\n",
    "    \n",
    "    print(val_acc)\n",
    "\n",
    "    predict_x= model_vgg16.predict(x_val) \n",
    "    predictions=np.argmax(predict_x,axis=1)\n",
    "    predictions = predictions.reshape(1,-1)[0]\n",
    "\n",
    "    print(classification_report(y_val, predictions, target_names = ['Benign (Class 0)','Malignant (Class 1)']))\n",
    "    cm = confusion_matrix(y_val, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()    \n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdf31b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Pretrained VGG16 Model Summary\n",
    "VGG16_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45f2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9b88e",
   "metadata": {},
   "source": [
    "## Run VGG16_2 on 200x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200X\n",
    "epochs = 50\n",
    "\n",
    "for i in range(len(train_set200)):\n",
    "    print(\"THIS IS FOLD\", i+1)\n",
    "    x_train, y_train, x_val, y_val = processing(train_set200[i], val_set200[i])\n",
    "    model_vgg16 = VGG16_2(x_train, y_train, x_val, y_val, epochs)\n",
    "    VGG_data(model_vgg16, epochs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925af34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
